---
title: Enable Semantic Search | OpenMetadata Deployment Guide
description: Configure semantic search with vector embeddings in OpenMetadata to enable natural language queries against your metadata catalog using OpenSearch.
sidebarTitle: Enable Semantic Search
---

# Enable Semantic Search

## Overview

Semantic Search enhances OpenMetadata's search capabilities by using **vector embeddings** to understand the meaning behind
queries, rather than relying solely on keyword matching. When enabled, entity metadata is converted into numerical vector
representations and stored in a dedicated OpenSearch index. At query time, the search text is also embedded and
K-Nearest Neighbor (KNN) similarity search is used to find the most relevant results.

This means users and AI agents can search using natural language -- for example, *"tables with customer demographics and
purchase history"* -- and get meaningful results even if those exact words don't appear in the metadata.

<Info>

Semantic Search is currently supported only with **OpenSearch** as the search backend. Elasticsearch support is planned
for a future release.

</Info>

Semantic Search also powers the [Semantic Search MCP tool](/v1.12.x-SNAPSHOT/how-to-guides/mcp/semantic-search),
enabling AI assistants connected via the Model Context Protocol to perform natural language queries against your
metadata catalog.

## How It Works

Semantic Search operates through the following pipeline:

<Steps>
  <Step title="Text Construction">
    For each entity, structured text is built from its metadata: name, description, entity type, service type,
    fully qualified name, tags, glossary terms, owners, tier, domains, and entity-specific fields such as column
    information for tables.
  </Step>
  <Step title="Text Chunking">
    The body text (description + columns) is split into chunks of up to 380 words. Each chunk is prepended with
    the structured metadata to form the final text to embed.
  </Step>
  <Step title="Fingerprint-Based Change Detection">
    An MD5 fingerprint of the text is computed before generating embeddings. If the fingerprint matches the existing
    one, embedding generation is skipped. This avoids redundant API calls when entity content has not changed.
  </Step>
  <Step title="Embedding Generation">
    Text chunks are sent to the configured embedding provider (OpenAI, AWS Bedrock, or DJL) which returns float
    vectors.
  </Step>
  <Step title="Vector Storage">
    Each chunk becomes a document in the `vector_search_index` OpenSearch index, stored alongside metadata fields
    for filtering. The index uses the HNSW (Hierarchical Navigable Small World) algorithm with cosine similarity.
  </Step>
  <Step title="Automatic Lifecycle Management">
    Embeddings are automatically created, updated, soft-deleted, hard-deleted, or restored in sync with entity
    lifecycle events. No manual intervention is required after initial setup.
  </Step>
</Steps>

### Supported Entity Types

Semantic Search supports the following entity types:

`table`, `glossary`, `glossaryTerm`, `chart`, `dashboard`, `dashboardDataModel`, `database`, `databaseSchema`,
`dataProduct`, `pipeline`, `mlmodel`, `metric`, `apiEndpoint`, `apiCollection`, `page`, `storedProcedure`,
`searchIndex`, `topic`

## Prerequisites

- **OpenSearch** as your search backend (Elasticsearch is not yet supported)
- An embedding provider: **OpenAI**, **AWS Bedrock**, or **DJL** (local, self-hosted)
- Network access from the OpenMetadata server to the embedding provider API (unless using DJL)

## Configuration

Semantic Search is configured in `openmetadata.yaml` under the `elasticsearch.naturalLanguageSearch` section.
All settings can be overridden with environment variables.

### Enable Semantic Search

| Environment Variable | Default | Description |
|---------------------|---------|-------------|
| `SEMANTIC_SEARCH_ENABLED` | `false` | Master switch to enable semantic search |
| `EMBEDDING_PROVIDER` | `bedrock` | Embedding provider to use: `openai`, `bedrock`, or `djl` |

```yaml
elasticsearch:
  naturalLanguageSearch:
    semanticSearchEnabled: ${SEMANTIC_SEARCH_ENABLED:-false}
    embeddingProvider: ${EMBEDDING_PROVIDER:-bedrock}
```

### Embedding Providers

Choose one of the following embedding providers and configure it accordingly.

<Tabs>
  <Tab title="OpenAI">
    Supports both OpenAI and Azure OpenAI endpoints.

    | Environment Variable | Default | Description |
    |---------------------|---------|-------------|
    | `OPENAI_API_KEY` | `""` | Your OpenAI API key |
    | `OPENAI_API_ENDPOINT` | `""` | API endpoint (for Azure: `https://your-resource.openai.azure.com`) |
    | `OPENAI_DEPLOYMENT_NAME` | `""` | Deployment name (required for Azure OpenAI) |
    | `OPENAI_API_VERSION` | `2024-02-01` | API version (Azure OpenAI) |
    | `OPENAI_EMBEDDING_MODEL_ID` | `text-embedding-3-small` | Embedding model to use |
    | `OPENAI_EMBEDDING_DIMENSION` | `1536` | Embedding vector dimension |

    ```yaml
    elasticsearch:
      naturalLanguageSearch:
        semanticSearchEnabled: true
        embeddingProvider: openai
        openai:
          apiKey: ${OPENAI_API_KEY:-""}
          endpoint: ${OPENAI_API_ENDPOINT:-""}
          deploymentName: ${OPENAI_DEPLOYMENT_NAME:-""}
          apiVersion: ${OPENAI_API_VERSION:-"2024-02-01"}
          embeddingModelId: ${OPENAI_EMBEDDING_MODEL_ID:-"text-embedding-3-small"}
          embeddingDimension: ${OPENAI_EMBEDDING_DIMENSION:-1536}
    ```
  </Tab>
  <Tab title="AWS Bedrock">
    Uses AWS Bedrock for embedding generation.

    | Environment Variable | Default | Description |
    |---------------------|---------|-------------|
    | `AWS_REGION` | `""` | AWS region |
    | `AWS_ACCESS_KEY_ID` | `""` | AWS access key |
    | `AWS_SECRET_ACCESS_KEY` | `""` | AWS secret access key |
    | `AWS_BEDROCK_EMBED_MODEL_ID` | `""` | Bedrock embedding model ID |
    | `AWS_BEDROCK_EMBEDDING_DIMENSION` | `""` | Embedding vector dimension |

    ```yaml
    elasticsearch:
      naturalLanguageSearch:
        semanticSearchEnabled: true
        embeddingProvider: bedrock
        bedrock:
          awsConfig:
            region: ${AWS_REGION:-""}
            accessKeyId: ${AWS_ACCESS_KEY_ID:-""}
            secretAccessKey: ${AWS_SECRET_ACCESS_KEY:-""}
          embeddingModelId: ${AWS_BEDROCK_EMBED_MODEL_ID:-""}
          embeddingDimension: ${AWS_BEDROCK_EMBEDDING_DIMENSION:-""}
    ```
  </Tab>
  <Tab title="DJL (Self-Hosted)">
    Uses [Deep Java Library](https://djl.ai/) to run embedding models locally. No external API calls required.

    | Environment Variable | Default | Description |
    |---------------------|---------|-------------|
    | `DJL_EMBEDDING_MODEL` | `ai.djl.huggingface.pytorch/sentence-transformers/all-MiniLM-L6-v2` | HuggingFace model identifier |

    The embedding dimension is auto-detected from the model at startup. The default model `all-MiniLM-L6-v2`
    produces 384-dimensional vectors.

    ```yaml
    elasticsearch:
      naturalLanguageSearch:
        semanticSearchEnabled: true
        embeddingProvider: djl
        djl:
          embeddingModel: ${DJL_EMBEDDING_MODEL:-"ai.djl.huggingface.pytorch/sentence-transformers/all-MiniLM-L6-v2"}
    ```
  </Tab>
</Tabs>

## Docker Deployment

To enable Semantic Search in a Docker deployment, set the required environment variables in your `docker-compose` override
or `.env` file:

```yaml
environment:
  SEMANTIC_SEARCH_ENABLED: "true"
  EMBEDDING_PROVIDER: "openai"
  OPENAI_API_KEY: "sk-..."
  OPENAI_EMBEDDING_MODEL_ID: "text-embedding-3-small"
  OPENAI_EMBEDDING_DIMENSION: "1536"
```

## Kubernetes Deployment

For Kubernetes deployments using the OpenMetadata Helm chart, add the environment variables to your `values.yaml`:

```yaml
openmetadata:
  config:
    extraEnvs:
      - name: SEMANTIC_SEARCH_ENABLED
        value: "true"
      - name: EMBEDDING_PROVIDER
        value: "openai"
      - name: OPENAI_API_KEY
        valueFrom:
          secretKeyRef:
            name: openmetadata-secrets
            key: openai-api-key
      - name: OPENAI_EMBEDDING_MODEL_ID
        value: "text-embedding-3-small"
      - name: OPENAI_EMBEDDING_DIMENSION
        value: "1536"
```

<Tip>

Store sensitive values like API keys in Kubernetes Secrets and reference them with `secretKeyRef` rather than
hardcoding them in `values.yaml`.

</Tip>

## Re-Embedding Existing Entities

After enabling Semantic Search for the first time (or after changing the embedding model), you need to generate
embeddings for all existing entities. Use the `reembed` CLI command:

```bash
./openmetadata-operations reembed \
  --batch-size 300 \
  --producer-threads 10 \
  --consumer-threads 5 \
  --queue-size 300
```

| Parameter | Default | Description |
|-----------|---------|-------------|
| `--batch-size` | 300 | Number of entities to process per batch |
| `--producer-threads` | 10 | Threads for reading entities |
| `--consumer-threads` | 5 | Threads for generating and indexing embeddings |
| `--queue-size` | 300 | Size of the internal processing queue |

This command drops the existing vector index, recreates it with the current configuration, and re-embeds all
supported entities.

<Warning>

The `reembed` command will temporarily make semantic search unavailable while it rebuilds the index. Plan to run
this during a maintenance window if you are in a production environment.

</Warning>

## API Reference

Semantic Search exposes a REST API endpoint for vector queries:

### POST `/api/v1/search/vector/query`

Performs a semantic search against the vector index.

**Request Body:**

```json
{
  "query": "customer demographics purchase history",
  "filters": {
    "entityType": ["table"],
    "owners": ["admin"],
    "tags": ["PII.Sensitive"],
    "domains": ["Marketing"],
    "tier": ["Tier.Tier1"],
    "serviceType": ["Postgres"]
  },
  "size": 10,
  "k": 1000,
  "threshold": 0.0
}
```

| Parameter | Type | Default | Description |
|-----------|------|---------|-------------|
| `query` | string | *(required)* | Natural language search text |
| `filters` | map | `{}` | Filter map by entity type, owners, tags, domains, tier, service type, certification, or custom properties |
| `size` | int | `10` | Number of distinct entities to return (max 100) |
| `k` | int | `1000` | KNN parameter -- number of nearest neighbors to consider (max 10,000) |
| `threshold` | double | `0.0` | Minimum similarity score to include in results |

Results are deduplicated by parent entity, so you will receive at most `size` distinct entities even if an entity has
multiple text chunks.

## Troubleshooting

### Semantic Search returns no results
- Verify that `SEMANTIC_SEARCH_ENABLED` is set to `true` and the server has been restarted.
- Confirm that OpenSearch is your search backend (Elasticsearch is not yet supported).
- Check that the `vector_search_index` exists in OpenSearch.
- Run the `reembed` command to generate embeddings for existing entities.

### Embedding generation fails
- Verify network connectivity from the OpenMetadata server to your embedding provider.
- Check that API keys and credentials are correct.
- Review the OpenMetadata server logs for detailed error messages.

### High memory usage
- The HNSW index can consume significant memory. Monitor OpenSearch heap usage.
- Consider reducing the `ef_search` or `m` parameters if memory is a concern (advanced users only -- requires index recreation).
