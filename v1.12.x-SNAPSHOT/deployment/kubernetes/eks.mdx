---
title: AWS EKS Deployment | OpenMetadata Kubernetes Guide
description: Deploy the OpenMetadata on Amazon EKS for cloud-native scalability with secure identity integration and managed infrastructure support.
sidebarTitle: Eks
collate: false
---

import FaqsEks from '/snippets/deployment/faqs-eks.mdx'
import Faqs from '/snippets/deployment/faqs.mdx'

# EKS on Amazon Web Services Deployment

OpenMetadata supports the Installation and Running of Application on Elastic Kubernetes Services (EKS) through Helm Charts.
However, there are some additional configurations which needs to be done as prerequisites for the same.

<Warning>

All the code snippets in this section assume the `default` namespace for kubernetes.
This guide presumes you have AWS EKS Cluster already available.

</Warning>

## Prerequisites

### AWS Services for Database as RDS and Search Engine as ElasticSearch

It is recommended to use [Amazon RDS](https://docs.aws.amazon.com/rds/index.html) and [Amazon OpenSearch Service](https://docs.aws.amazon.com/opensearch-service/?id=docs_gateway) for Production Deployments.

We support

- Amazon RDS (MySQL) engine version 8 or higher
- Amazon RDS (PostgreSQL) engine version 12 or higher
- Amazon OpenSearch engine version 2.X (upto 2.19)

<Tip>
When using AWS Services the SearchType Configuration for elastic search should be `opensearch`, for both cases ElasticSearch and OpenSearch, as you can see in the ElasticSearch configuration example below.
</Tip>

We recommend
- Amazon RDS to be in Multiple Availability Zones.
- Amazon OpenSearch (or ElasticSearch) Service with Multiple Availability Zones with minimum 2 Nodes.

<Warning>
Make sure to increase `sort_buffer_size` (for MySQL) or `work_mem` (for PostgreSQL) to the recommended value of **20MB** or more using the [database parameter group setting](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html). This is especially important when running migrations to prevent **Out of Sort Memory Error**. You can revert the setting once the migrations are complete.
</Warning>

## Kubernetes Orchestrator Configuration (Recommended)

Starting with OpenMetadata 1.12, we recommend using the **Kubernetes native orchestrator** for running ingestion pipelines. This eliminates the need for Apache Airflow and simplifies your deployment.

<Tip>
The Kubernetes orchestrator runs ingestion pipelines as native K8s Jobs and CronJobs. For full documentation, see the [Kubernetes Orchestrator Guide](/v1.12.x-SNAPSHOT/deployment/ingestion/kubernetes).
</Tip>

### OpenMetadata Values Configuration

Create your `openmetadata-values.yaml` with the following configuration:

```yaml
# openmetadata-values.yaml
openmetadata:
  config:
    # Database configuration
    elasticsearch:
      host: <AMAZON_OPENSEARCH_SERVICE_ENDPOINT_WITHOUT_HTTPS>
      searchType: opensearch
      port: 443
      scheme: https
      connectionTimeoutSecs: 5
      socketTimeoutSecs: 60
      keepAliveTimeoutSecs: 600
      batchSize: 10
      auth:
        enabled: true
        username: <AMAZON_OPENSEARCH_USERNAME>
        password:
          secretRef: elasticsearch-secrets
          secretKey: openmetadata-elasticsearch-password
    database:
      host: <AMAZON_RDS_ENDPOINT>
      port: 3306
      driverClass: com.mysql.cj.jdbc.Driver
      dbScheme: mysql
      dbUseSSL: true
      databaseName: <RDS_DATABASE_NAME>
      auth:
        username: <RDS_DATABASE_USERNAME>
        password:
          secretRef: mysql-secrets
          secretKey: openmetadata-mysql-password

    # Kubernetes Orchestrator configuration
    pipelineServiceClientConfig:
      enabled: true
      type: "k8s"
      metadataApiEndpoint: http://openmetadata:8585/api
      
      k8s:
        className: "org.openmetadata.service.clients.pipeline.k8s.K8sPipelineClient"
        ingestionImage: "docker.getcollate.io/openmetadata/ingestion-base:1.12.0"
        imagePullPolicy: "IfNotPresent"
        serviceAccountName: "openmetadata-ingestion"
        
        # Use OMJob Operator for guaranteed exit handlers (recommended)
        useOMJobOperator: true
        
        # Job settings
        ttlSecondsAfterFinished: 86400
        activeDeadlineSeconds: 7200
        backoffLimit: 3
        
        # Resource limits
        resources:
          limits:
            cpu: "2"
            memory: "4Gi"
          requests:
            cpu: "500m"
            memory: "1Gi"
        
        # Enable failure diagnostics (requires OMJob Operator)
        enableFailureDiagnostics: true
        rbac:
          enabled: true

# Enable the OMJob Operator (recommended for production)
omjobOperator:
  enabled: true
  image:
    repository: docker.getcollate.io/openmetadata/omjob-operator
    tag: "1.12.0"
```

### Create Kubernetes Secrets

Create the required secrets for RDS and OpenSearch:

```bash
# Database secret
kubectl create secret generic mysql-secrets \
  --from-literal=openmetadata-mysql-password=<YOUR_RDS_PASSWORD>

# OpenSearch secret
kubectl create secret generic elasticsearch-secrets \
  --from-literal=openmetadata-elasticsearch-password=<YOUR_OPENSEARCH_PASSWORD>
```

### Deploy OpenMetadata

```bash
# Add the OpenMetadata Helm repository
helm repo add open-metadata https://helm.open-metadata.org/
helm repo update

# Install OpenMetadata (no dependencies chart needed with K8s orchestrator)
helm install openmetadata open-metadata/openmetadata \
  --values openmetadata-values.yaml
```

<Tip>
With the Kubernetes orchestrator, you don't need to deploy the `openmetadata-dependencies` chart that includes Airflow. This significantly simplifies your deployment.
</Tip>

### Verify the Deployment

```bash
# Check pods are running
kubectl get pods

# Check the K8s orchestrator health in OpenMetadata UI
# Navigate to Settings → Preferences → Health
```

---

## Using Airflow Orchestrator (Alternative)

If you prefer to use Apache Airflow as the orchestrator (e.g., for existing Airflow investments or complex DAG requirements), follow the configuration below.

<Warning>
Using Airflow requires additional infrastructure: persistent volumes with ReadWriteMany access, the openmetadata-dependencies Helm chart, and more complex configuration.
</Warning>

### Create Elastic File System in AWS

You can follow official AWS Guides [here](https://docs.aws.amazon.com/efs/latest/ug/gs-step-two-create-efs-resources.html) to provision EFS File System in the same VPC which is associated with your EKS Cluster.

### Persistent Volumes with ReadWriteMany Access Modes

OpenMetadata helm chart depends on Airflow and Airflow expects a persistent disk that support ReadWriteMany (the volume can be mounted as read-write by many nodes).

In AWS, this is achieved by Elastic File System (EFS) service. AWS Elastic Block Store (EBS) does not provide ReadWriteMany Volume access mode as EBS will only be attached to one Kubernetes Node at any given point of time.

In order to provision persistent volumes from AWS EFS, you will need to setup and install [aws-efs-csi-driver](https://docs.aws.amazon.com/eks/latest/userguide/efs-csi.html). Note that this is required for Airflow as One OpenMetadata Dependencies.

Also, [aws-ebs-csi-driver](https://docs.aws.amazon.com/eks/latest/userguide/ebs-csi.html) might be required for Persistent Volumes that are to be used for MySQL and ElasticSearch as OpenMetadata Dependencies.

The below guide provides Persistent Volumes provisioning as static volumes (meaning you will be responsible to create, maintain and destroy Persistent Volumes).

### Provision EFS backed PVs, PVCs for Airflow DAGs and Airflow Logs

Please note that we are using one AWS Elastic File System (EFS) service with subdirectories as `airflow-dags` and `airflow-logs` with the reference in this documentation. Also, it is presumed that `airflow-dags` and `airflow-logs` directories are already available on that file system.

In order to create directories inside the AWS Elastic File System (EFS) you would need to follow these [steps](https://docs.aws.amazon.com/efs/latest/ug/accessing-fs-nfs-permissions-per-user-subdirs.html).

#### Code Samples for PV and PVC for Airflow DAGs

```yaml
# dags_pv_pvc.yml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: openmetadata-dependencies-dags-pv
  labels:
    app: airflow-dags
spec:
  capacity:
    storage: 10Gi
  storageClassName: ""
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  csi:
    driver: efs.csi.aws.com
    volumeHandle: <FileSystemId>:/airflow-dags # Replace with EFS File System Id

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  labels:
    app: airflow-dags
  name: openmetadata-dependencies-dags-pvc
  namespace: default
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: ""
  resources:
    requests:
      storage: 10Gi
```

Create Persistent Volumes and Persistent Volume claims with the below command.

```commandline
kubectl create -f dags_pv_pvc.yml
```

#### Code Samples for PV and PVC for Airflow Logs

```yaml
# logs_pv_pvc.yml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: openmetadata-dependencies-logs-pv
  labels:
    app: airflow-logs
spec:
  capacity:
    storage: 5Gi
  storageClassName: ""
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  csi:
    driver: efs.csi.aws.com
    volumeHandle: <FileSystemId>:/airflow-logs # Replace with EFS File System Id

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: openmetadata-dependencies-logs-pvc
  namespace: default
  labels:
    app: airflow-dags
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: ""
  resources:
    requests:
      storage: 5Gi
```

Create Persistent Volumes and Persistent Volume claims with the below command.

```commandline
kubectl create -f logs_pv_pvc.yml
```

### Change owner and permission manually on disks

Since airflow pods run as non root users, they would not have write access on the nfs server volumes. In order to fix the permission here, spin up a pod with persistent volumes attached and run it once.

You can find more reference on AWS EFS permissions in docs [here](https://docs.aws.amazon.com/efs/latest/ug/using-fs.html).

```yaml
# permissions_pod.yml
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: my-permission-pod
  name: my-permission-pod
spec:
  containers:
  - image: nginx
    name: my-permission-pod
    volumeMounts:
    - name: airflow-dags
      mountPath: /airflow-dags
    - name: airflow-logs
      mountPath: /airflow-logs
    command:
    - "chown -R 50000 /airflow-dags /airflow-logs"
    # if needed
    - "chmod -R a+rwx /airflow-dags"
  volumes:
  - name: airflow-logs
    persistentVolumeClaim:
      claimName: openmetadata-dependencies-logs-pvc
  - name: airflow-dags
    persistentVolumeClaim:
      claimName: openmetadata-dependencies-dags-pvc
  dnsPolicy: ClusterFirst
  restartPolicy: Always
```

<Tip>

Airflow runs the pods with linux user name as airflow and linux user id as 50000.

</Tip>

Run the below command to create the pod and fix the permissions

```commandline
kubectl create -f permissions_pod.yml
```

### Create OpenMetadata dependencies Values

Override openmetadata dependencies airflow helm values to bind the efs persistent volumes for DAGs and logs.

```yaml
# values-dependencies.yml
airflow:
  airflow:
    extraVolumeMounts:
      - mountPath: /airflow-logs
        name: efs-airflow-logs
      - mountPath: /airflow-dags/dags
        name: efs-airflow-dags
    extraVolumes:
      - name: efs-airflow-logs
        persistentVolumeClaim:
          claimName: openmetadata-dependencies-logs-pvc
      - name: efs-airflow-dags
        persistentVolumeClaim:
          claimName: openmetadata-dependencies-dags-pvc
    config:
      AIRFLOW__OPENMETADATA_AIRFLOW_APIS__DAG_GENERATED_CONFIGS: "/airflow-dags/dags"
  dags:
    path: /airflow-dags/dags
    persistence:
      enabled: false
  logs:
    path: /airflow-logs
    persistence:
      enabled: false
```

For more information on airflow helm chart values, please refer to [airflow-helm](https://artifacthub.io/packages/helm/airflow-helm/airflow/8.5.3).

When deploying openmetadata dependencies helm chart, use the below command -

```commandline
helm install openmetadata-dependencies open-metadata/openmetadata-dependencies --values values-dependencies.yaml
```

<Tip>

The above command uses configurations defined [here](https://raw.githubusercontent.com/open-metadata/openmetadata-helm-charts/main/charts/deps/values.yaml).
You can modify any configuration and deploy by passing your own `values.yaml`

```commandline
helm install openmetadata-dependencies open-metadata/openmetadata-dependencies --values <path-to-values-file>
```

</Tip>

### Deploy OpenMetadata with Airflow Configuration

Create your OpenMetadata values file with Airflow configuration:

```yaml
# openmetadata-values-airflow.yaml
openmetadata:
  config:
    elasticsearch:
      host: <AMAZON_OPENSEARCH_SERVICE_ENDPOINT_WITHOUT_HTTPS>
      searchType: opensearch
      port: 443
      scheme: https
      connectionTimeoutSecs: 5
      socketTimeoutSecs: 60
      keepAliveTimeoutSecs: 600
      batchSize: 10
      auth:
        enabled: true
        username: <AMAZON_OPENSEARCH_USERNAME>
        password:
          secretRef: elasticsearch-secrets
          secretKey: openmetadata-elasticsearch-password
    database:
      host: <AMAZON_RDS_ENDPOINT>
      port: 3306
      driverClass: com.mysql.cj.jdbc.Driver
      dbScheme: mysql
      dbUseSSL: true
      databaseName: <RDS_DATABASE_NAME>
      auth:
        username: <RDS_DATABASE_USERNAME>
        password:
          secretRef: mysql-secrets
          secretKey: openmetadata-mysql-password
    
    # Airflow configuration
    pipelineServiceClientConfig:
      enabled: true
      type: "airflow"
      metadataApiEndpoint: http://openmetadata:8585/api
      airflow:
        apiEndpoint: http://openmetadata-dependencies-web:8080
        auth:
          username: admin
          password:
            secretRef: airflow-secrets
            secretKey: openmetadata-airflow-password
```

Once the openmetadata dependencies helm chart deployed, you can then run the below command to install the openmetadata helm chart -

```commandline
helm install openmetadata open-metadata/openmetadata --values openmetadata-values-airflow.yaml
```

Make sure to create RDS and OpenSearch credentials as Kubernetes Secrets mentioned [here](/quick-start/local-kubernetes-deployment#2.-create-kubernetes-secrets-required-for-helm-charts).

Also, disable MySQL and ElasticSearch from OpenMetadata Dependencies Helm Charts as mentioned in the FAQs [here](#how-to-disable-mysql-and-elasticsearch-from-openmetadata-dependencies-helm-charts).

## FAQs

<FaqsEks />

<Faqs />